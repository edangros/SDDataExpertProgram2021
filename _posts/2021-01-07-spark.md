---
layout: post
title: "Spark"
date: 2021-01-07 19:42:11 UTC+9
comments: false
---

# Spark

## Spark 탄생의 배경
[하둡](hadoop.md)의 특징을 생각해보자. 하둡은 수많은 특징들이 있지만 아래 내용은 실질적인 데이터처리에 있어서 문제로 작용한다.
* 하둡은 데이터의 지연을 줄이는 방향보다는 한번에 처리할 수 있는 처리 용량, 즉 입출력 데이터의 대역폭을 넓히는 것을 중점으로 하고 있다. 다시 말해 데이터의 실시간 반응은 느리다.
* 하둡의 MapReduce는 데이터를 HDFS로부터 읽어 처리하고 중간 결과도 HDFS에 저장한다. 다시 말해, 모든 데이터는 보조기억장치 내에서 로드되어 처리된다. 인메모리 처리가 되지 않는다는 점은 하둡 작업의 속도를 크게 늦출 수 밖에 없다.

이에 대해 하둡 시스템은 Hadoop2에서부터 큰 변화를 주어 YARN이 도입되고, MapReduce 대신 다른 연산 플랫폼을 사용할 수 있도록 하였다. 이에 임팔라(impale) 등의 인메모리 대화형 처리 장치, 하이브(Hive) 등의 SQL과 유사한 처리 장치 등이 고안되어 사용될 수 있게 되었다.

그러한 환경은 이전에 비해 진일보한 빅데이터 처리 환경을 만들 수 있게 하였으나, 수많은 환경이 생김으로 인해 빅데이터 분석가 입장에서는 툴 학습에 대한 부담이 크게 증가하였다.

스팍은 그러한 환경을 하나의 툴로 통합하여, 작업 스케쥴링과 메모리 관리, 장애 복구, 저장장치 연동(이상의 기능은 Hadoop YARN이 제공해왔음), SQL 유사 쿼리(Hive가 제공해왔음), 스트리밍(Kafka가 제공해왔음), 머신러닝(각종 머신러닝 솔루션으로 대체해야 했음), 그래프를 통한 시각화(hive, mahout을 사용해야 했음)을 하나의 프레임워크 내에서 처리할 수 있게 만들었다.

## Spark의 구성 요소
* spark core : 작업 스케쥴링, 메모리 관리, 장애 복구, 저장장치 연동 등 spark 어플리케이션이 작동하는 전반적인 사항을 처리한다.
* spark SQL : SQL DB, Hive Table, json 등 다양한 데이터 소스로부터 쿼리해온 데이터를 처리할 수 있다.
* spark stream : 실시간 데이터 스트림을 처리할 수 있다.
* MLLib : 머신 러닝용 라이브러리
* GraphX : 그래프 작성 라이브러리

## Spark의 컴포넌트

**RDD**

변하지 않고 분산된 레코드의 집합. Kafka와 마찬가지로 분산되어 여러 클러스터 노드에 저장, 안정적으로 작동됨. 값이 변하지 않으므로 만들어질 때의 초기값만 안다면 다시 만들어낼 수 있음

* DAG : SPL의 표현식과 유사한 연산
* Dataframe : Pandas의 Dataframe과 유사한 테이블 형태 데이터. SQL과 유사하게 데이터 쿼리 가능

**계속 작성 필요**

## Spark의 특징
* 인메모리 연산 : Spark는 데이터를 메모리에 로드해 메모리에서 빠르게 연산해낸다.
* 결함내성 : Spark 또한 파티션을 복제하여 사용, 일부 노드의 손상도 복구해낼 수 있다.
* 단일 플랫폼 : Spark는 단일 플랫폼에서 데이터 획득, 배치, 스트리밍, 머신러닝, 시각화까지 할 수 있다.
* 비의존성 : Spark는 다양한 데이터 소스를 받아 다양한 플랫폼으로 처리, 전송할 수 있으며, 파이썬, R, 자바, 스칼라 등 다양한 언어로 된 SDK를 제공한다.

## Spark vs Hadoop
* 참고자료 : [hadoop vs spark](https://logz.io/blog/hadoop-vs-spark/)

개념적으로 볼 때, Spark와 Hadoop의 가장 큰 차이점은 데이터 처리의 과정이다. Hadoop의 MapReduce는 모든 데이터를 보조기억장치(하드디스크)에 쓰고 저장하며 작업을 진행한다. 따라서 메모리 대역폭에 여유를 가지는 대신 입출력 속도는 극도로 느려지게 된다. Spark는 임팔라와 마찬가지로 인메모리 연산을 진행하기 때문에 연산의 속도가 빠르다.

또한 Spark는 각 단계 사이에서의 최적화가 가능하기 때문에 각 단계가 따로 실행되는 Hadoop MapReduce에 비해 최적화에도 유리하다. 하지만 이러한 유저와의 상호작용을 고려하지 않고, 배치 파일에 의해 실행되는 데이터 연산만을 할 경우, Spark가 YAML 위에서 실행될 시 속도가 느려지고 잘못할 시 RAM 오버헤드 메모리 누수가 발생할 수도 있다.

보안 및 안정성에 있어서는 Hadoop이 더 유리하다. 하둡의 HDFS는 각종 보안 솔루션을 적용 가능하고, HDFS의 원리에 의해 안정성 또한 보장된다. Spark는 그에 비해 적용 가능한 보안수단이 적고, 실행자와 드라이버 오류에 따라 데이터가 복제되면서도 오염될 가능성이 존재한다.

이 글만 보면 양립할 수 없어보이지만, 하둡과 스팍 시스템은 동시에 사용 가능하며 그 예시는 [인트로](intro.md)에 나와있다. 

## Spark vs Kafka
스파크 스트림 | 카프카 스트림
---|---
전송받은 데이터는 마이크로단위의 입력 스트림으로 쪼개짐 | 한개의 데이터 스트림당 한개의 프로세스
서로 쪼개져있는 프로세싱 클러스터 필요 | 프로세싱 클러스터가 쪼개져있을 필요 없음(하나의 머신에서 실행 가능)
스케일링시 재설정 필요 | 자바 프로세스 하나만 추가하면 스케일 가능. 추가 설정 필요 없음
여러 그룹의 줄을 처리하는데에 유리(그룹, ml, 윈도우 기능 등) | 한 시점당 한 개의 레코드를 처리하는데에 유리.(필요없는 데이터 제거 등)
단독 프레임워크임 | 여러 마이크로서비스의 일부로 사용 가능. 라이브러리임.
