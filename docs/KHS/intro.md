# Kafka, Hadoop, Spark

아파치의 3대 빅데이터 프레임워크.


## 빅데이터의 3대 요소

우선적으로 위 3가지 솔루션으로 처리해야 할 '빅데이터'가 무엇인지를 알아야 한다. 아래의 두 가지 정의가 보편적으로 사용된다.
* **데이터의 규모**가 너무 커 기존 데이터베이스 관리도구의 데이터 수집/저장/관리/분석 역량으로는 처리가 불가능한 데이터 (맥킨지)
* 기존과 다른 **업무 수행 방식**을 통해 *다양한 종류*의 *대규모* 데이터로부터 저렴한 비용으로 가치를 추출하고, 데이터의 빠른 수집/저장/발굴/분석을 지원하도록 고안된 차세대 기술과 아기텍쳐(IDC)


빅데이터의 3대 요소는 아래의 3가지(3V) 를 보통 말한다. 이 중 두가지 이상의 요소가 충족되면 빅데이터라 볼 수 있다.

### 크기(Volume)
* 수십 TB, 또는 PB 이상의 데이터
* 기존 파일 시스템으로는 저장조차 버거운 크기로, 분석은 더더욱 어려움
* 분산된 클러스터(Cluster) 형태의 처리장치가 요구되며, 클라우드(Cloud) 시스템과 결합되기도 함
* 구글의 GFS, 아파치의 Hadoop 등

### 속도(Velocity)
* 실시간 처리 : 데이터가 쌓이는 속도가 매우 빠르기 때문에 수집/저장/분석을 실시간으로 할 수 있어야 함
* 장기적 접근 : 그와 동시에 다양한 분석 기법과 표현을 위해 장기적인 접근 또한 필요함
* 자연어 처리, 패턴 인식, 데이터 마이닝, 머신러닝 등 대용량의 비정형 데이터를 효과적으로 처리하기 위한 기법 필요

### 다양성(Variety)
* 빅데이터는 비정형 데이터를 처리할 수 있어야 함
* 정형(고정된 필드에 저장되는 일정한 형식, 즉 SQL에 저장가능한 형식)
* 반정형(필드는 고정되지 않지만 어느정도의 스키마를 따라가는 형식. HTML이나 XML 등)
* **비정형 데이터는 고정된 필드가 정의될 수 없음. 사진, 동영상, 포스팅이나 채팅 내용 등**
  * (여기서 채팅 데이터 자체는 정형 데이터로 처리가 가능하지만, *채팅으로 친 내용*은 비정형임에 유의)
  
따라서, 채팅 데이터는 TB단위가 아니어도 빅데이터(Velocity + Variety)

센서데이터는 TB단위로 쌓일 경우 빅데이터(Volume + Velocity)

망해서 데이터가 더이상 쌓이지 않는 싸이월드의 데이터도 빅데이터(Volume + Variety)

---

---

## Kafka, Hadoop, Spark를 사용한 데이터 프로세스 예시
셋의 역할과 차이를 알아보기 위해서는 예시를 통해서 파악하는 게 필요

예시는 시스템의 일부며, 서로간의 역할은 조정되거나, 다른 외부 솔루션을 사용할 수도 있음

아래 내용은 [Jayesh Nazre의 2017년 블로그 포스트](https://pmtechfusion.blogspot.com/2017/11/big-datadata-science-analytics-apache_20.html)에 기반하고 있으며
그동안 프레임워크에 일어난 변화를 반영하기 위해 다음 내용을 참고하였음
* [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
* [그로윈 하둡 제품 설명](https://www.growin.co.kr/hadoop)


### Hadoop
---
![그로윈 하둡 에코시스템 설명](https://static.wixstatic.com/media/b0bfeb_84e43b0fda7b414f885618f992d7b7f7~mv2.png/v1/fill/w_750,h_518,al_c,q_90,usm_0.66_1.00_0.01/hadoop01.webp)
Hadoop(하둡)은 분산형 데이터의 저장 및 처리를 위해 만들어진 프레임워크로 아래와 같은 모듈로 구성됨
* HDFS : 빅데이터 저장을 위한 분산형 파일 저장시스템
* MapReduce : 빅데이터의 처리를 위한 실행 프레임워크. 병렬 배치 연산(MapReduce)기능을 사용
  * 아파치에서는 차세대 프레임워크 Apache Tez를 배포하고 있음
* YARN : 클러스터의 자원 및 스케줄링을 담당
이 아키텍쳐 예재에서는 아래와 같은 역할을 담당
* 빅데이터 처리를 위해 **Kafka 사용자\(Consumers\)** 가 사용
* **Spark**의 출력 결과를 저장
* 클러스터의 종합 관리자로 사용( **YARN** )

### Kafka
-----

