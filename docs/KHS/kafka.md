# Kafka
해당 포스트는 아래 글을 기반으로 작성되었다.
* [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
* [www.joinc.co.kr의 Kafka 페이지](https://www.joinc.co.kr/w/man/12/Kafka)

카프카는 분산 스트리밍 플랫폼(Distributed streaming platform)이다. 이 역할을 이해하기 위해서는 단어들의 의미를 상기할 필요가 있다.
* 분산(Distribution)은 장치가 한 곳에 존재하지 않는다는 것을 의미한다. 다시 말해 하나의 장치(Machine)가 아닌 클러스터(Cluster) 상에서 작동한다.
* 스트리밍은 데이터가 일시적으로 전달되지 않고, 지속적으로 전달됨을 의미한다. MySQL에서 쿼리 결과를 전송하듯이 한 번에 처리되는 것이 아닌, 데이터를 스트림 형태로 제공하는 [Hadoop](hadoop.md)와 어울리는 시스템이다.
* 플랫폼은 한 가지 기능을 수행하는 것이 아니라 여러 어플리케이션이 카프카의 모델을 사용하여 작업을 진행할 수 있음을 의미한다.
<br><br>

## 이벤트 스트리밍(Event Streaming)

카프카는 분산 스트리밍 플랫폼이자 이벤트 스트리밍 플랫폼이다. 이벤트 스트리밍은 중추 신경계의 디지털 버전으로, '항상 켜져있는' 세계의 기본이다. '항상 켜져있는' 세계에서는 비즈니스들이 갈수록 소프트웨어에 의해 행해지고 자동화되며, 소프트웨어를 사람이 아닌 소프트웨어가 사용하게 된다.

기술적으로는, 이벤트 스트리밍은 데이터베이스, 센서, 모바일 장치, 각종 소프트웨어 등에서 실시간으로 발생하는 이벤트들로부터 데이터를 수집하여 동시에 실시간으로 반응하고, 해당 데이터가 필요한 곳으로 데이터를 다시 스트리밍하는 시스템이다. 이러한 연속적인 데이터의 흐름과 해석을 통해 필요한 데이터가 필요한 곳에, 필요한 때 전달될 수 있도록 할 수 있다.

다양한 종류의 산업에서 이러한 이벤트 스트리밍이 사용될 수 있으며 사용되고 있다. 예를 들면,
* **실시간으로** 주식이나 은행 계좌, 보험 등에서의 금전 거래를 처리하기
* 자동차 산업과 운송 산업에서 트럭, 자동차, 선박 등과 선적물을 **실시간으로** 추적하고 관리하기
* **실시간으로** IoT 장비들의 데이터를 수집하고 분석하기.
* 소매업, 숙박업, 여행업, 또는 모바일 앱 시장에서 사용자의 반응과 주문이 발생하는 순간 **즉각적으로** 대응하기.
* 병원 환자를 관리하고 문제를 예측하여 비상시에 **즉각적으로** 조치를 취할 수 있게 준비하기
* 회사의 각 부서들이 **지속적으로** 만들어내는 데이터를 수집하고 저장하고 즉시 사용할 수 있게 가공하기.
* 플랫폼, 마이크로서비스, 이벤트 기반 아키텍쳐의 기반 모델로 사용

위의 내용으로부터 카프카의 핵심 특성은 '실시간'과 '지속성'. 즉 **스트림**에 중심을 두고 있음을 알 수 있다.
<br><br>

## 이벤트 스트리밍 플랫폼으로써의 카프카
카프카는 위의 영역에서 사용가능할 수 있게 아래의 세 가지 기본 기능을 제공한다.
* 이벤트 스트림을 **게시**(publish = write)하고 **구독**(subscribe = read)할 수 있다. 이러한 요소는 다른 시스템과 실시간으로 입/출력된다.
* 안정적이고 신뢰성 있게, 원하는 기간만큼 이러한 이벤트 스트림을 **저장**할 수 있다.
* 이벤트가 발생한 시점에, 또는 이후에 소급적으로 이벤트를 처리할 수 있다.

또한 카프카는 위의 기능을 아래의 특성을 가진 채 제공된다.
* 분산성(Distributed). 카프카는 물리적 하드웨어, 가상머신, 컨테이너, 기업 맞춤형 장치, 클라우드 등에 로드될 수 있다.
* 스케일 가능(Scalable). 카프카는 여러 개의 머신으로 빠르고 간편하게 배포되어 기능을 수행할 수 있다. 수요에 맞추어 클러스터의 크기를 탄력적(elastic)으로 조절 가능하다.
* 내결함성(fault-tolerant). 카프카는 노드, 또는 입력에서 발생한 문제에 대해 내성을 가지고 있다.
* 보안성(secure). 카프카에 의한 통신 내역은 보안성을 가지고 있다.

카프카의 서버는 하나 혹은 여러 서버로 구성된 클러스터로 작동하며 여러 데이터센터나 클라우드 지역으로 확장될 수 있다. 일부 서버는 **브로커**(broker)로 불리며, 이들은 저장 계층을 형성한다. 다른 서버는 Kafka Connect를 실행시켜 지속적으로 데이터를 이벤트 스트림의 형태로 입력받고 출력한다. 이러한 이벤트 스트림을 통해 DB 등의 어플리케이션이나 다른 카프카 시스템과 통신할 수 있다. 또한 카프카는 스케일링 가능하며 내결함성을 가지고 있어, 하나의 카프카 서버가 고장날 시, 다른 카프카 서버들이 데이터 손실 없이 작업을 이어받아 지속적으로 작동할 수 있다.

카프카의 클라이언트는 분산된 어플리케이션과 마이크로서비스로, 이벤트 스트림을 읽고, 쓰고, 가공한다. 이들 카프카 클라이언트 또한 병렬적이고, 스케일 가능하며, 내결함성을 가져 네트워크 결함이나 하드웨어 고장과 같은 오류 상황에서도 작동 가능하다. 카프카 클라이언트는 다양한 언어로 작성되었으며, 자바와 스칼라에 기반된 라이브러리를 기반으로, Go, 파이썬, C/C++, REST API 등 다양한 언어에서 사용 가능하다.

<br><br>

## 카프카에서 사용되는 개념과 용어
### 이벤트(Event)
이벤트는 세계에서 '무언가가 일어났음'에 대한 기록이다. 이는 '레코드' 또는 '메세지'라고도 불린다. 카프카에 데이터를 읽거나 쓸 때, 모든 것은 이벤트의 형태로 이루어진다. 이벤트는 키(key), 값(value), 발생시간(timestamp)과 추가적인 메타데이터 헤더로 이루어져 있다.

### 생산자(Producer)와 소비자(Consumers)
생산자는 카프카에 데이터를 쓰는 클라이언트, 소비자는 카프카로부터 데이터를 받는 클라이언트이다. 카프카에서 이 둘은 완전히 따로 존재할 수 있으며, 서로에 대해 인지하지 못한 채로도 동작 가능하다. 이렇게 분리된 구조를 통해 카프카는 스케일링 가능한 구조를 얻을 수 있었다. 예를 들어, 생산자는 소비자에게 이벤트가 전달되었는지를 확인하고 기다릴 필요 없이, 카프카에게 데이터를 건낼 수 있으며, 소비자 또한 카프카로부터 데이터를 항상 받아들일 필요 없이, 받아들일 필요와 여유가 있을 때에만 받을 수 있다.

### 이벤트와 토픽(Topic)
카프카에서 이벤트는 '토픽'에 따라 조직화되고 저장된다. 토픽은 파일시스탬에서의 폴더와 유사하며 이벤트는 그 폴더 내부의 파일이라고도 볼 수 있다. 예를 들어, '지불 내역'이라는 토픽에 모든 유저의 결재 내역 이벤트가 저장될 수 있다.

이러한 토픽은 항상 다수의 생산자와 구독자를 가질 수 있으며, 때로는 아예 가지지 않을 수도 있다. 토픽 내의 이벤트는 필요할 때마다 계속 구독 가능하며, 기존의 메세지 시스템과 달리 소비자에 의해 소비된 뒤에도 사라지지 않는다. 그 대신, 카프카 시스템에서는 토픽마다 해당 토픽 내의 이벤트가 얼마나 저장되어야 하는지를 정의할 수 있다. 

## 카프카에서의 저장
![카프카 파티션](https://kafka.apache.org/images/streams-and-tables-p1_p4.png)
카프카에서 토픽들은 파티션화되어 있다. 다시 말해, 각 토픽은 서로 다른 카프카 **브로커**에 위치해 저장될 수 있다. 이렇게 분산되어 저장됨으로써 카프카 시스템은 스케일링 가능하다. 각각의 생산자와 소비자는 서로 다른 카프카 브로커로부터 데이터를 동시에 받아 실시간으로 빠르게 이벤트 스트림을 제공받을 수 있기 때문이다.

어떠한 이벤트가 토픽에 제공되면, 토픽의 파티션 중 하나에 해당 토픽의 로그가 덧붙여진다. 같은 키를 가진 이벤트는 같은 파티션에 저장되며, 카프카는 이벤트가 쓰여진 순서대로 저장되고, 쓰여진 순서대로 읽을 수 있음을 보장한다. 이는 자료구조 중 큐(Que)와 유사한 형태이다.

또한 안정성을 위해 [하둡](hadoop.md)의 블록과 마찬가지로 토픽의 파티션 또한 복제되어 다수가 노드들(여기서는 브로커)에 중복 저장된다. 다수의 브로커가 같은 토픽 파티션을 가지고 있으며, 한 브로커가 고장났을 경우 다른 브로커를 통해 토픽의 내용을 복구할 수 있다. 기본적으로 하둡과 마찬가지로 토픽의 복제 횟수는 3이다.

## 카프카 API
![카프카 개념도](https://drive.google.com/uc?export=view&id=0B6p_m8EvqxeuU00zeHRFOHNaa2M)

카프카는 어플리케이션이 사용할 API를 아래와 같이 가지고 있다.
* 생산자(Producer) : 카프카의 특정 토픽에 스트림 레코드를 기록할 수 있는 어플리케이션
* 소비자(Consumer) : 카프카의 특정 토픽에 대한 스트림 레코드를 읽을 수 있는 어플리케이션
* 스트림(Streams) : 카프카의 특정 토픽의 입력 스트림을 읽고 가공, 출력 토픽에 레코드를 기록할 수 있는 어플리케이션
* 커넥터(Connector) : 재사용 가능한 생산자/소비자를 카프카 토픽에 연결할 수 있는 어플리케이션. 예를 들면, 데이터베이스 내의 커넥터는 테이블에 대한 변경 사항을 캡쳐, 그 변경 내역을 특정 카프카 토픽으로 연결할 수 있다.
